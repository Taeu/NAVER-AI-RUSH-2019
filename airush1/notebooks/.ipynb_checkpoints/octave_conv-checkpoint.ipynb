{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OctaveConv\n",
    "\n",
    "- https://github.com/ThoroughImages/OctConv/blob/master/demo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from octconv import OctConv2d, OctReLU, OctMaxPool2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading FashionMNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data',\n",
    "                                      train=True,\n",
    "                                      transform=transform,\n",
    "                                      download=True)\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(root='./data',\n",
    "                                     train=False,\n",
    "                                     transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=batch_size, \n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MNIST Dataset\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OctCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convs = nn.Sequential(OctConv2d('first', in_channels=1, out_channels=32, kernel_size=3),\n",
    "                                   OctReLU(),\n",
    "                                   OctConv2d('regular', in_channels=32, out_channels=64, kernel_size=3),\n",
    "                                   OctReLU(),\n",
    "                                   OctConv2d('regular', in_channels=64, out_channels=128, kernel_size=3),\n",
    "                                   OctReLU(),\n",
    "                                   OctMaxPool2d(2),\n",
    "                                   OctConv2d('regular', in_channels=128, out_channels=128, kernel_size=3),\n",
    "                                   OctReLU(),\n",
    "                                   OctConv2d('last', in_channels=128, out_channels=128, kernel_size=3),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2),\n",
    "                                  )\n",
    "        self.fc = nn.Sequential(nn.Linear(6272, 256),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.Linear(256, 10)\n",
    "                                )\n",
    "    \n",
    "    \n",
    "    def forward(self, x):  \n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, x.size(1) * x.size(2) * x.size(3))\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OctCNN()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 20 Loss: 0.4314352571964264. Accuracy: 84.040000\n",
      "Iteration: 40 Loss: 0.4153634309768677. Accuracy: 84.680000\n",
      "Iteration: 60 Loss: 0.4263860881328583. Accuracy: 83.880000\n",
      "Iteration: 80 Loss: 0.46227744221687317. Accuracy: 84.760000\n",
      "Iteration: 100 Loss: 0.5090758204460144. Accuracy: 84.670000\n",
      "Iteration: 120 Loss: 0.38190385699272156. Accuracy: 84.940000\n",
      "Iteration: 140 Loss: 0.3928123116493225. Accuracy: 85.410000\n",
      "Iteration: 160 Loss: 0.36810436844825745. Accuracy: 85.840000\n",
      "Iteration: 180 Loss: 0.393439918756485. Accuracy: 85.660000\n",
      "Iteration: 200 Loss: 0.3972342610359192. Accuracy: 86.050000\n",
      "Iteration: 220 Loss: 0.37476593255996704. Accuracy: 85.910000\n",
      "Iteration: 240 Loss: 0.3133814334869385. Accuracy: 85.850000\n",
      "Iteration: 260 Loss: 0.3304150700569153. Accuracy: 86.060000\n",
      "Iteration: 280 Loss: 0.3528797924518585. Accuracy: 86.230000\n",
      "Iteration: 300 Loss: 0.30910128355026245. Accuracy: 86.170000\n",
      "Iteration: 320 Loss: 0.34352603554725647. Accuracy: 86.510000\n",
      "Iteration: 340 Loss: 0.3979418873786926. Accuracy: 86.530000\n",
      "Iteration: 360 Loss: 0.33797186613082886. Accuracy: 86.520000\n",
      "Iteration: 380 Loss: 0.3077066242694855. Accuracy: 86.540000\n",
      "Iteration: 400 Loss: 0.3452511131763458. Accuracy: 87.070000\n",
      "Iteration: 420 Loss: 0.3573402166366577. Accuracy: 87.130000\n",
      "Iteration: 440 Loss: 0.3697189688682556. Accuracy: 86.990000\n",
      "Iteration: 460 Loss: 0.3357967734336853. Accuracy: 86.780000\n",
      "Iteration: 480 Loss: 0.3518287241458893. Accuracy: 86.960000\n",
      "Iteration: 500 Loss: 0.39641472697257996. Accuracy: 87.380000\n",
      "Iteration: 520 Loss: 0.2983587086200714. Accuracy: 87.210000\n",
      "Iteration: 540 Loss: 0.3242945373058319. Accuracy: 87.070000\n",
      "Iteration: 560 Loss: 0.3401358723640442. Accuracy: 87.320000\n",
      "Iteration: 580 Loss: 0.30907946825027466. Accuracy: 87.410000\n",
      "Iteration: 600 Loss: 0.34969475865364075. Accuracy: 87.530000\n",
      "Iteration: 620 Loss: 0.26821407675743103. Accuracy: 87.650000\n",
      "Iteration: 640 Loss: 0.30492186546325684. Accuracy: 87.600000\n",
      "Iteration: 660 Loss: 0.31302446126937866. Accuracy: 87.360000\n",
      "Iteration: 680 Loss: 0.3253832757472992. Accuracy: 87.660000\n",
      "Iteration: 700 Loss: 0.32830163836479187. Accuracy: 87.690000\n",
      "Iteration: 720 Loss: 0.26594382524490356. Accuracy: 87.800000\n",
      "Iteration: 740 Loss: 0.2604939043521881. Accuracy: 87.860000\n",
      "Iteration: 760 Loss: 0.3259393870830536. Accuracy: 88.250000\n",
      "Iteration: 780 Loss: 0.2779551148414612. Accuracy: 87.740000\n",
      "Iteration: 800 Loss: 0.3238052725791931. Accuracy: 88.210000\n",
      "Iteration: 820 Loss: 0.28655585646629333. Accuracy: 88.030000\n",
      "Iteration: 840 Loss: 0.26769712567329407. Accuracy: 88.160000\n",
      "Iteration: 860 Loss: 0.31150251626968384. Accuracy: 88.260000\n",
      "Iteration: 880 Loss: 0.26299113035202026. Accuracy: 88.200000\n",
      "Iteration: 900 Loss: 0.2920885384082794. Accuracy: 88.410000\n",
      "Iteration: 920 Loss: 0.26452964544296265. Accuracy: 88.310000\n",
      "Iteration: 940 Loss: 0.2914361357688904. Accuracy: 88.660000\n",
      "Iteration: 960 Loss: 0.29986587166786194. Accuracy: 88.300000\n",
      "Iteration: 980 Loss: 0.23692426085472107. Accuracy: 88.090000\n",
      "Iteration: 1000 Loss: 0.261037141084671. Accuracy: 88.050000\n",
      "Iteration: 1020 Loss: 0.294467955827713. Accuracy: 88.380000\n",
      "Iteration: 1040 Loss: 0.23460891842842102. Accuracy: 88.540000\n",
      "Iteration: 1060 Loss: 0.25746360421180725. Accuracy: 88.750000\n",
      "Iteration: 1080 Loss: 0.27550366520881653. Accuracy: 88.090000\n",
      "Iteration: 1100 Loss: 0.23301354050636292. Accuracy: 88.600000\n",
      "Iteration: 1120 Loss: 0.29071080684661865. Accuracy: 88.610000\n",
      "Iteration: 1140 Loss: 0.2725202739238739. Accuracy: 88.920000\n",
      "Iteration: 1160 Loss: 0.30123960971832275. Accuracy: 89.000000\n",
      "Iteration: 1180 Loss: 0.31783509254455566. Accuracy: 89.050000\n",
      "Iteration: 1200 Loss: 0.3113122880458832. Accuracy: 88.620000\n",
      "Iteration: 1220 Loss: 0.22601661086082458. Accuracy: 88.750000\n",
      "Iteration: 1240 Loss: 0.3348850905895233. Accuracy: 89.130000\n",
      "Iteration: 1260 Loss: 0.25866273045539856. Accuracy: 88.890000\n",
      "Iteration: 1280 Loss: 0.2887616753578186. Accuracy: 89.110000\n",
      "Iteration: 1300 Loss: 0.2507669925689697. Accuracy: 89.180000\n",
      "Iteration: 1320 Loss: 0.26857614517211914. Accuracy: 88.550000\n",
      "Iteration: 1340 Loss: 0.263394832611084. Accuracy: 89.070000\n",
      "Iteration: 1360 Loss: 0.21890859305858612. Accuracy: 89.090000\n",
      "Iteration: 1380 Loss: 0.28847962617874146. Accuracy: 88.750000\n",
      "Iteration: 1400 Loss: 0.2528274655342102. Accuracy: 89.160000\n",
      "Iteration: 1420 Loss: 0.1800340861082077. Accuracy: 88.820000\n",
      "Iteration: 1440 Loss: 0.25450384616851807. Accuracy: 89.440000\n",
      "Iteration: 1460 Loss: 0.2694191336631775. Accuracy: 89.410000\n",
      "Iteration: 1480 Loss: 0.28749164938926697. Accuracy: 89.440000\n",
      "Iteration: 1500 Loss: 0.2411993443965912. Accuracy: 89.070000\n",
      "Iteration: 1520 Loss: 0.22970479726791382. Accuracy: 89.500000\n",
      "Iteration: 1540 Loss: 0.21277391910552979. Accuracy: 89.020000\n",
      "Iteration: 1560 Loss: 0.2148256152868271. Accuracy: 89.300000\n",
      "Iteration: 1580 Loss: 0.25087910890579224. Accuracy: 89.600000\n",
      "Iteration: 1600 Loss: 0.2298537641763687. Accuracy: 89.810000\n",
      "Iteration: 1620 Loss: 0.2676343023777008. Accuracy: 89.850000\n",
      "Iteration: 1640 Loss: 0.24504224956035614. Accuracy: 89.190000\n",
      "Iteration: 1660 Loss: 0.186289981007576. Accuracy: 89.460000\n",
      "Iteration: 1680 Loss: 0.23570524156093597. Accuracy: 89.540000\n",
      "Iteration: 1700 Loss: 0.27754098176956177. Accuracy: 89.790000\n",
      "Iteration: 1720 Loss: 0.21330566704273224. Accuracy: 89.650000\n",
      "Iteration: 1740 Loss: 0.27363014221191406. Accuracy: 89.500000\n",
      "Iteration: 1760 Loss: 0.24458517134189606. Accuracy: 90.100000\n",
      "Iteration: 1780 Loss: 0.2215093970298767. Accuracy: 89.340000\n",
      "Iteration: 1800 Loss: 0.21415075659751892. Accuracy: 89.960000\n",
      "Iteration: 1820 Loss: 0.20218124985694885. Accuracy: 89.970000\n",
      "Iteration: 1840 Loss: 0.21898610889911652. Accuracy: 90.000000\n",
      "Iteration: 1860 Loss: 0.24924467504024506. Accuracy: 90.010000\n",
      "Iteration: 1880 Loss: 0.3031388223171234. Accuracy: 90.180000\n",
      "Iteration: 1900 Loss: 0.23164960741996765. Accuracy: 90.130000\n",
      "Iteration: 1920 Loss: 0.22644637525081635. Accuracy: 90.020000\n",
      "Iteration: 1940 Loss: 0.216128408908844. Accuracy: 89.940000\n",
      "Iteration: 1960 Loss: 0.21646791696548462. Accuracy: 90.080000\n",
      "Iteration: 1980 Loss: 0.259615957736969. Accuracy: 90.420000\n",
      "Iteration: 2000 Loss: 0.2277275025844574. Accuracy: 89.860000\n",
      "Iteration: 2020 Loss: 0.2037188857793808. Accuracy: 90.210000\n",
      "Iteration: 2040 Loss: 0.20671376585960388. Accuracy: 90.020000\n",
      "Iteration: 2060 Loss: 0.26360011100769043. Accuracy: 89.980000\n",
      "Iteration: 2080 Loss: 0.21486030519008636. Accuracy: 89.960000\n",
      "Iteration: 2100 Loss: 0.24893155694007874. Accuracy: 90.100000\n",
      "Iteration: 2120 Loss: 0.24594907462596893. Accuracy: 90.110000\n",
      "Iteration: 2140 Loss: 0.15084344148635864. Accuracy: 90.080000\n",
      "Iteration: 2160 Loss: 0.2266004979610443. Accuracy: 90.440000\n",
      "Iteration: 2180 Loss: 0.2629365622997284. Accuracy: 90.320000\n",
      "Iteration: 2200 Loss: 0.239641472697258. Accuracy: 89.710000\n",
      "Iteration: 2220 Loss: 0.20371390879154205. Accuracy: 90.300000\n",
      "Iteration: 2240 Loss: 0.24998153746128082. Accuracy: 90.310000\n",
      "Iteration: 2260 Loss: 0.22234538197517395. Accuracy: 90.280000\n",
      "Iteration: 2280 Loss: 0.25010067224502563. Accuracy: 90.050000\n",
      "Iteration: 2300 Loss: 0.19036994874477386. Accuracy: 90.060000\n",
      "Iteration: 2320 Loss: 0.22488990426063538. Accuracy: 90.560000\n",
      "Iteration: 2340 Loss: 0.21294212341308594. Accuracy: 90.450000\n",
      "Iteration: 2360 Loss: 0.21240466833114624. Accuracy: 90.770000\n",
      "Iteration: 2380 Loss: 0.256803035736084. Accuracy: 90.370000\n",
      "Iteration: 2400 Loss: 0.2162061333656311. Accuracy: 90.410000\n",
      "Iteration: 2420 Loss: 0.20492921769618988. Accuracy: 90.820000\n",
      "Iteration: 2440 Loss: 0.19336479902267456. Accuracy: 90.880000\n",
      "Iteration: 2460 Loss: 0.2057981789112091. Accuracy: 90.090000\n",
      "Iteration: 2480 Loss: 0.20994463562965393. Accuracy: 90.650000\n",
      "Iteration: 2500 Loss: 0.22268632054328918. Accuracy: 90.710000\n",
      "Iteration: 2520 Loss: 0.17395301163196564. Accuracy: 90.570000\n",
      "Iteration: 2540 Loss: 0.23334281146526337. Accuracy: 90.770000\n",
      "Iteration: 2560 Loss: 0.2212037444114685. Accuracy: 90.660000\n",
      "Iteration: 2580 Loss: 0.19624024629592896. Accuracy: 90.340000\n",
      "Iteration: 2600 Loss: 0.17287585139274597. Accuracy: 90.750000\n",
      "Iteration: 2620 Loss: 0.23679472506046295. Accuracy: 90.800000\n",
      "Iteration: 2640 Loss: 0.2082143872976303. Accuracy: 90.800000\n",
      "Iteration: 2660 Loss: 0.18369397521018982. Accuracy: 90.880000\n",
      "Iteration: 2680 Loss: 0.20588214695453644. Accuracy: 90.710000\n",
      "Iteration: 2700 Loss: 0.20847322046756744. Accuracy: 91.030000\n",
      "Iteration: 2720 Loss: 0.24622443318367004. Accuracy: 90.760000\n",
      "Iteration: 2740 Loss: 0.18633149564266205. Accuracy: 90.380000\n",
      "Iteration: 2760 Loss: 0.2004789412021637. Accuracy: 90.920000\n",
      "Iteration: 2780 Loss: 0.17588530480861664. Accuracy: 90.840000\n",
      "Iteration: 2800 Loss: 0.1664154827594757. Accuracy: 90.920000\n",
      "Iteration: 2820 Loss: 0.18508662283420563. Accuracy: 91.160000\n",
      "Iteration: 2840 Loss: 0.1849995255470276. Accuracy: 90.690000\n",
      "Iteration: 2860 Loss: 0.24686302244663239. Accuracy: 91.000000\n",
      "Iteration: 2880 Loss: 0.19029885530471802. Accuracy: 90.710000\n",
      "Iteration: 2900 Loss: 0.20795975625514984. Accuracy: 90.990000\n",
      "Iteration: 2920 Loss: 0.24217469990253448. Accuracy: 91.130000\n",
      "Iteration: 2940 Loss: 0.222649484872818. Accuracy: 90.910000\n",
      "Iteration: 2960 Loss: 0.19213330745697021. Accuracy: 90.630000\n",
      "Iteration: 2980 Loss: 0.15844853222370148. Accuracy: 91.190000\n",
      "Iteration: 3000 Loss: 0.18185438215732574. Accuracy: 90.700000\n",
      "Iteration: 3020 Loss: 0.21233195066452026. Accuracy: 90.850000\n",
      "Iteration: 3040 Loss: 0.1932542473077774. Accuracy: 91.230000\n",
      "Iteration: 3060 Loss: 0.1856945902109146. Accuracy: 91.260000\n",
      "Iteration: 3080 Loss: 0.181568443775177. Accuracy: 91.010000\n",
      "Iteration: 3100 Loss: 0.17327505350112915. Accuracy: 90.920000\n",
      "Iteration: 3120 Loss: 0.1914566457271576. Accuracy: 90.620000\n",
      "Iteration: 3140 Loss: 0.18854714930057526. Accuracy: 91.000000\n",
      "Iteration: 3160 Loss: 0.18771159648895264. Accuracy: 90.880000\n",
      "Iteration: 3180 Loss: 0.24188359081745148. Accuracy: 90.900000\n",
      "Iteration: 3200 Loss: 0.16949562728405. Accuracy: 89.920000\n",
      "Iteration: 3220 Loss: 0.20833919942378998. Accuracy: 90.730000\n",
      "Iteration: 3240 Loss: 0.15830007195472717. Accuracy: 91.060000\n",
      "Iteration: 3260 Loss: 0.15016789734363556. Accuracy: 91.100000\n",
      "Iteration: 3280 Loss: 0.17758408188819885. Accuracy: 91.290000\n",
      "Iteration: 3300 Loss: 0.1504121720790863. Accuracy: 91.060000\n",
      "Iteration: 3320 Loss: 0.15185092389583588. Accuracy: 91.010000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        num_iter += 1\n",
    "        \n",
    "        if num_iter % 20 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    images, labels = images.cuda(), labels.cuda()\n",
    "                    \n",
    "                images = Variable(images)\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().detach().cpu()\n",
    "            \n",
    "            accuracy = 100 * (correct.item() / total)\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {} Loss: {}. Accuracy: {:4f}'.format(num_iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
